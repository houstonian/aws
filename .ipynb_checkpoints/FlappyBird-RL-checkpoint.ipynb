{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import skimage as skimage\n",
    "from skimage import transform, color, exposure\n",
    "from skimage.transform import rotate\n",
    "from skimage.viewer import ImageViewer\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import wrapped_flappy_bird as game\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import json\n",
    "from keras import initializers\n",
    "#from keras import initializations\n",
    "from keras.initializers import normal, identity\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAME = 'bird'               # the name of the game being played for log files\n",
    "CONFIG = 'nothreshold'\n",
    "ACTIONS = 2                 # number of valid actions\n",
    "GAMMA = 0.99                # decay rate of past observations\n",
    "OBSERVATION = 3200.         # 3200 timesteps to observe before training\n",
    "EXPLORE = 3000000.          # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001      # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1       # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000       # number of previous transitions to remember\n",
    "BATCH = 32                  # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "img_rows , img_cols = 80, 80\n",
    "#Convert image into Black and white\n",
    "img_channels = 4 #We stack 4 frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 8, 8, subsample=(4, 4), border_mode='same',input_shape=(img_rows,img_cols,img_channels)))  #80*80*4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 4, 4, subsample=(2, 2), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "   \n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    print(\"We finish building the model\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNetwork(model,args):\n",
    "    # open up a game state to communicate with emulator\n",
    "    game_state = game.GameState()\n",
    "    \n",
    "    # store the previous observations in replay memory\n",
    "    D = deque()\n",
    "\n",
    "    # get the first state by doing nothing and preprocess the image to 80x80x4\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] = 1\n",
    "    x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "\n",
    "    x_t = skimage.color.rgb2gray(x_t)\n",
    "    x_t = skimage.transform.resize(x_t,(80,80))\n",
    "    x_t = skimage.exposure.rescale_intensity(x_t,out_range=(0,255))\n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "    #print (s_t.shape)\n",
    "\n",
    "    #In Keras, need to reshape\n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*80*80*4\n",
    "\n",
    "    \n",
    "\n",
    "    if args['mode'] == 'Run':\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        model.load_weights(\"./run/model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = INITIAL_EPSILON\n",
    "\n",
    "    t = 0\n",
    "    while (True):\n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0\n",
    "        a_t = np.zeros([ACTIONS])\n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0:\n",
    "            if random.random() <= epsilon:\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else:\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)\n",
    "                action_index = max_Q\n",
    "                a_t[max_Q] = 1\n",
    "\n",
    "        #We reduced the epsilon gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "\n",
    "        x_t1 = skimage.color.rgb2gray(x_t1_colored)\n",
    "        x_t1 = skimage.transform.resize(x_t1,(80,80))\n",
    "        x_t1 = skimage.exposure.rescale_intensity(x_t1, out_range=(0, 255))\n",
    "\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x80x80x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3)\n",
    "\n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "        #model.load_weights(\"./model.h5\")\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE:\n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "\n",
    "\n",
    "\n",
    "            inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 80, 80, 4\n",
    "            print (inputs.shape)\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]\n",
    "                state_t1 = minibatch[i][3]\n",
    "                terminal = minibatch[i][4]\n",
    "                # if terminated, only equals reward\n",
    "\n",
    "                inputs[i:i + 1] = state_t    #I saved down s_t\n",
    "\n",
    "                targets[i] = model.predict(state_t)  # Hitting each buttom probability\n",
    "                Q_sa = model.predict(state_t1)\n",
    "\n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            # targets2 = normalize(targets)\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "\n",
    "        s_t = s_t1\n",
    "        t = t + 1\n",
    "\n",
    "        # save progress every 10000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            model.save_weights(\"model.h5\", overwrite=True)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        #print(\"TIMESTEP\", t, \"/ STATE\", state, \\\n",
    "        #    \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t, \\\n",
    "        #    \"/ Q_MAX \" , np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def playGame(args):\n",
    "    model = buildmodel()\n",
    "    trainNetwork(model,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='Description of your program')\n",
    "#parser.add_argument('-m','--mode', help='Train / Run', required=True)\n",
    "#args = vars(parser.parse_args())\n",
    "#playGame(args)\n",
    "playGame({'mode': 'Run'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "keras-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
